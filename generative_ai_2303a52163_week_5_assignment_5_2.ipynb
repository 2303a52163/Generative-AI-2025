{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a52163/Generative-AI-2025/blob/main/generative_ai_2303a52163_week_5_assignment_5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1st Question:-**\n",
        "1. (1 ponto) Design a multi-layer ANN architecture with one input, one hidden, and one output\n",
        "layer. Assume a linear activation function in the output layer and a sigmoid activation function\n",
        "in the hidden layer.\n",
        "• Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table\n",
        "1.\n",
        "• Calculate the mean square error with training and testing data shown in Table 2.\n",
        "• Write Python code that reads the input data [x1 and x2] from the user. Predict the output\n",
        "with deployed ANN model\n",
        "\n",
        "Tabela 1: Training Data\n",
        "\n",
        "x1   x2    y\n",
        "\n",
        "0.2 0.1 0.3441\n",
        "\n",
        "0.3 0.2 0.3500\n",
        "\n",
        "0.4 0.3 0.3558\n",
        "\n",
        "0.7 0.6 0.3729\n",
        "\n",
        "0.8 0.7 0.3785\n",
        "\n",
        "0.9 0.8 0.3841\n",
        "\n",
        "Tabela 2: Test Data\n",
        "\n",
        "x1 x2 y\n",
        "\n",
        "0.5 0.4 0.3615\n",
        "\n",
        "0.6 0.5 0.3672"
      ],
      "metadata": {
        "id": "kkXlUh2Q5pGB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x38UleYz0kLA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of Sigmoid Function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Mean Squared Error Function\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data (Tabla 1)\n",
        "X_train = np.array([[0.2, 0.1], [0.3, 0.2], [0.4, 0.3], [0.7, 0.6], [0.8, 0.7], [0.9, 0.8]])\n",
        "y_train = np.array([[0.3441], [0.3500], [0.3558], [0.3729], [0.3785], [0.3841]])\n",
        "\n",
        "# Test Data (Tabla 2)\n",
        "X_test = np.array([[0.5, 0.4], [0.6, 0.5]])\n",
        "y_test = np.array([[0.3615], [0.3672]])\n"
      ],
      "metadata": {
        "id": "sh2rU5RQ2ont"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_neurons = 2  # (x1, x2)\n",
        "hidden_neurons = 4\n",
        "output_neurons = 1\n",
        "learning_rate = 0.1\n",
        "epochs = 5000\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Initialize Weights and Biases\n",
        "weights_input_hidden = np.random.rand(input_neurons, hidden_neurons)\n",
        "weights_hidden_output = np.random.rand(hidden_neurons, output_neurons)\n",
        "bias_hidden = np.random.rand(1, hidden_neurons)\n",
        "bias_output = np.random.rand(1, output_neurons)\n"
      ],
      "metadata": {
        "id": "7yGp76ye2rTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Process with Backpropagation\n",
        "for epoch in range(epochs):\n",
        "# Forward Propagation\n",
        "    hidden_layer_input = np.dot(X_train, weights_input_hidden) + bias_hidden\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
        "    output_layer_output = output_layer_input\n",
        "\n",
        "    # Compute Error\n",
        "    error = y_train - output_layer_output\n",
        "\n",
        "    # Backpropagation\n",
        "    d_output = error\n",
        "    error_hidden_layer = d_output.dot(weights_hidden_output.T)\n",
        "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "    # Update Weights and Biases using Gradient Descent\n",
        "    weights_hidden_output += hidden_layer_output.T.dot(d_output) * learning_rate\n",
        "    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "    weights_input_hidden += X_train.T.dot(d_hidden_layer) * learning_rate\n",
        "    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n"
      ],
      "metadata": {
        "id": "HGJc6Uwd2vRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions and MSE Calculation\n",
        "hidden_train = sigmoid(np.dot(X_train, weights_input_hidden) + bias_hidden)\n",
        "y_pred_train = np.dot(hidden_train, weights_hidden_output) + bias_output\n",
        "\n",
        "hidden_test = sigmoid(np.dot(X_test, weights_input_hidden) + bias_hidden)\n",
        "y_pred_test = np.dot(hidden_test, weights_hidden_output) + bias_output\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse_train = mse(y_train, y_pred_train)\n",
        "mse_test = mse(y_test, y_pred_test)\n",
        "\n",
        "print(\"Mean Squared Error on Training Data:\", mse_train)\n",
        "print(\"Mean Squared Error on Test Data:\", mse_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHKaBV_p2z-O",
        "outputId": "eafead95-2178-4a40-b044-bb48b9ff5133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error on Training Data: 4.8331435377022174e-08\n",
            "Mean Squared Error on Test Data: 1.6126925776635128e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User Input Prediction\n",
        "while True:\n",
        "    try:\n",
        "        x1, x2 = map(float, input(\"Enter values for x1 and x2 (comma-separated): \").split(\",\"))\n",
        "        break  # Exit the loop if input is valid\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter two values separated by a comma.\")\n",
        "\n",
        "user_input = np.array([[x1, x2]])\n",
        "\n",
        "# Predict Output\n",
        "hidden_user = sigmoid(np.dot(user_input, weights_input_hidden) + bias_hidden)\n",
        "prediction = np.dot(hidden_user, weights_hidden_output) + bias_output\n",
        "print(\"Predicted Output:\", prediction[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9czUkV7Cq0N",
        "outputId": "8484f8b7-659d-4dd8-c807-1a500b3d18fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter values for x1 and x2 (comma-separated): 4.8 , 1.6\n",
            "Predicted Output: 0.45480176519158744\n"
          ]
        }
      ]
    }
  ]
}